dataset_name: maud_specific_performance
dataset_path: nguha/legalbench
doc_to_choice:
- A
- B
doc_to_target: '{{answer}}'
group: legalbench_interpretation
group_alias: interpretation
include: ../prompt_templates/maud_specific_performance/base_prompt.yaml
metric_list:
- aggregation: balanced_acc
  higher_is_better: true
  metric: balanced_acc
output_type: multiple_choice
task: maud_specific_performance
test_split: test
training_split: train
